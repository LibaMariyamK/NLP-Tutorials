{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3293f6",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa7d51",
   "metadata": {},
   "source": [
    "TF-IDF is a method used in NLP to convert text into numerical vectors. It gives importance to words that are more **unique** in a document and reduces the weight of very common words.\n",
    "\n",
    "**TF (Term Frequency):** Measures how often a word appears in a document.  \n",
    "  \n",
    "$$\n",
    "TF(t) = \\frac{\\text{Number of times term } t \\text{ appears in a document}}{\\text{Total number of terms in the document}}\n",
    "$$\n",
    "\n",
    "**IDF (Inverse Document Frequency):** Measures how important a word is across multiple documents.  \n",
    "  \n",
    "$$\n",
    "IDF(t) = \\log \\frac{\\text{Total number of documents}}{1 + \\text{Number of documents containing term } t}\n",
    "$$\n",
    "\n",
    "**TF-IDF:** Combines both TF and IDF.  \n",
    "  \n",
    "$$\n",
    "TFIDF(t) = TF(t) \\times IDF(t)\n",
    "$$\n",
    "\n",
    "### Why TF-IDF is used\n",
    "\n",
    "* Filters out common words like “the”, “is”, “and” that appear in almost all documents.\n",
    "* Highlights words that carry more meaning for a document.\n",
    "* Useful for **search engines**, **text classification**, **spam detection**, and **recommendation systems**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ae00d",
   "metadata": {},
   "source": [
    "### Step-by-Step TF-IDF Calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a625b0f7",
   "metadata": {},
   "source": [
    "Let's take three sample sentences:\n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    \"I love pizza and pasta\",\n",
    "    \"Pizza is my favorite food\",\n",
    "    \"I love eating pasta\"\n",
    "]\n",
    "```\n",
    "\n",
    "**Step 1: Compute Term Frequency (TF)**\n",
    "Count the occurrences of each word in a document and divide by total words in that document.\n",
    "\n",
    "Example for document 1: `\"I love pizza and pasta\"`\n",
    "\n",
    "* Total words: 5\n",
    "* TF(\"I\") = 1/5 = 0.2\n",
    "* TF(\"love\") = 1/5 = 0.2\n",
    "* TF(\"pizza\") = 1/5 = 0.2\n",
    "* TF(\"and\") = 1/5 = 0.2\n",
    "* TF(\"pasta\") = 1/5 = 0.2\n",
    "\n",
    "**Step 2: Compute Inverse Document Frequency (IDF)**\n",
    "\n",
    "* Count how many documents contain each word:\n",
    "\n",
    "  * \"I\" → 2 documents\n",
    "  * \"love\" → 2\n",
    "  * \"pizza\" → 2\n",
    "  * \"and\" → 1\n",
    "  * \"pasta\" → 2\n",
    "  * \"is\" → 1\n",
    "  * \"my\" → 1\n",
    "  * \"favorite\" → 1\n",
    "  * \"food\" → 1\n",
    "  * \"eating\" → 1\n",
    "\n",
    "* Total documents = 3\n",
    "\n",
    "$$\n",
    "IDF(t) = \\log\\frac{3}{1 + df(t)}\n",
    "$$\n",
    "\n",
    "* Example:\n",
    "\n",
    "  * IDF(\"I\") = log(3 / (2+1)) = log(1) = 0\n",
    "  * IDF(\"and\") = log(3 / (1+1)) = log(1.5) ≈ 0.176\n",
    "\n",
    "**Step 3: Multiply TF by IDF**\n",
    "[\n",
    "TFIDF(\"word\") = TF(\"word\") * IDF(\"word\")\n",
    "]\n",
    "\n",
    "This gives the final TF-IDF vector for each document.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a4bb4",
   "metadata": {},
   "source": [
    "### Implementing TF-IDF using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5027e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eating</th>\n",
       "      <th>eating pasta</th>\n",
       "      <th>favorite</th>\n",
       "      <th>favorite food</th>\n",
       "      <th>food</th>\n",
       "      <th>love</th>\n",
       "      <th>love eating</th>\n",
       "      <th>love pizza</th>\n",
       "      <th>pasta</th>\n",
       "      <th>pizza</th>\n",
       "      <th>pizza favorite</th>\n",
       "      <th>pizza pasta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.51742</td>\n",
       "      <td>0.393511</td>\n",
       "      <td>0.393511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.51742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355432</td>\n",
       "      <td>0.467351</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.373022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eating  eating pasta  favorite  favorite food      food      love  \\\n",
       "0  0.000000      0.000000  0.000000       0.000000  0.000000  0.393511   \n",
       "1  0.000000      0.000000  0.467351       0.467351  0.467351  0.000000   \n",
       "2  0.490479      0.490479  0.000000       0.000000  0.000000  0.373022   \n",
       "\n",
       "   love eating  love pizza     pasta     pizza  pizza favorite  pizza pasta  \n",
       "0     0.000000     0.51742  0.393511  0.393511        0.000000      0.51742  \n",
       "1     0.000000     0.00000  0.000000  0.355432        0.467351      0.00000  \n",
       "2     0.490479     0.00000  0.373022  0.000000        0.000000      0.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love pizza and pasta\",\n",
    "    \"Pizza is my favorite food\",\n",
    "    \"I love eating pasta\"\n",
    "]\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),stop_words='english')\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert TF-IDF matrix to array\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Display TF-IDF values\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tfidf_array, columns=feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d871fc2",
   "metadata": {},
   "source": [
    "You will get a table where rows represent documents and columns represent words. Each value is the TF-IDF score.\n",
    "\n",
    "\n",
    "### Key Notes \n",
    "\n",
    "* TF-IDF reduces the weight of common words across documents.\n",
    "* Words unique to a document get higher importance.\n",
    "* It's widely used for text preprocessing in ML/NLP before applying classification or clustering.\n",
    "* Can be used for **feature extraction** in models like Naive Bayes, Logistic Regression, and SVM.\n",
    "\n",
    "\n",
    "### Tips\n",
    "\n",
    "* Use `TfidfVectorizer(stop_words='english')` to remove common English words automatically.\n",
    "* Can combine with **n-grams** to capture phrases: `TfidfVectorizer(ngram_range=(1,2))`.\n",
    "* Always fit TF-IDF on training data only, then transform test data to avoid data leakage.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
