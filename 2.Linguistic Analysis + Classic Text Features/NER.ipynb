{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46005a5",
   "metadata": {},
   "source": [
    "# üåü **NER (Named Entity Recognition)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6a0a6",
   "metadata": {},
   "source": [
    "NER is a task in NLP where the model **finds important real-world entities** in text and assigns labels like:\n",
    "PERSON, ORG (organization), GPE (countries, cities, states), DATE, MONEY, PRODUCT, etc.\n",
    "\n",
    "Example:\n",
    "**‚ÄúApple released the iPhone in California.‚Äù**\n",
    "\n",
    "| Word       | Entity  |\n",
    "| ---------- | ------- |\n",
    "| Apple      | ORG     |\n",
    "| iPhone     | PRODUCT |\n",
    "| California | GPE     |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê Why NER is used\n",
    "\n",
    "* Resume parsing\n",
    "* Chatbots\n",
    "* Search engines\n",
    "* Medical reports\n",
    "* Invoice extraction\n",
    "* News understanding\n",
    "* Legal document automation\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠êHow NER Works\n",
    "\n",
    "NER uses:\n",
    "\n",
    "‚úî **Rule-based NER**\n",
    "\n",
    "Uses patterns (regex, dictionaries).\n",
    "Simple but weak.\n",
    "\n",
    "‚úî **Statistical / ML-based NER**\n",
    "\n",
    "SVM, CRF (old but used in classic NLP).\n",
    "\n",
    "‚úî **Neural NER (current trend)**\n",
    "\n",
    "spaCy, BERT, RoBERTa, transformers ‚Üí highest accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab063c",
   "metadata": {},
   "source": [
    "# ‚≠ê Basic NER using spaCy (Built-in Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37334ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google - ORG\n",
      "John - PERSON\n",
      "London - GPE\n",
      "5 million dollars - MONEY\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Google hired John in London for 5 million dollars.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"-\", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1628b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " hired \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5 million dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spaCy NER Visualization (Optional)\n",
    "\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fb0eb",
   "metadata": {},
   "source": [
    "### ‚≠ê Understanding Common NER Labels\n",
    "\n",
    "| Label   | Meaning              |\n",
    "| ------- | -------------------- |\n",
    "| PERSON  | Human names          |\n",
    "| ORG     | Company, institution |\n",
    "| GPE     | Countries, cities    |\n",
    "| LOC     | Locations            |\n",
    "| DATE    | Dates                |\n",
    "| TIME    | Times                |\n",
    "| MONEY   | Monetary values      |\n",
    "| PRODUCT | Device, product      |\n",
    "| EVENT   | Festive/event names  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7476e3d",
   "metadata": {},
   "source": [
    "#### spaCy NER may be inaccurate\n",
    "\n",
    "Because:\n",
    "\n",
    "* Small training data\n",
    "* ‚Äúsm‚Äù model is small\n",
    "* Domain-mismatch\n",
    "* New/unseen entities\n",
    "* Not trained on Indian names/places well\n",
    "\n",
    "**Fix:**\n",
    "Use `en_core_web_trf` (transformer).\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_trf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8112f099",
   "metadata": {},
   "source": [
    "## When to use Transformers (BERT NER)\n",
    "\n",
    "If your requirements are:\n",
    "\n",
    "* High accuracy\n",
    "* Domain-specific text\n",
    "* Uncommon entities\n",
    "* Large labels\n",
    "\n",
    "Use HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45303237",
   "metadata": {},
   "source": [
    "### Simple NER using BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c9dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1844865fac324e12af3237d4cce846f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  79%|#######9  | 1.06G/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--dbmdz--bert-large-cased-finetuned-conll03-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "text = \"Elon Musk founded SpaceX in California.\"\n",
    "\n",
    "result = ner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6634e178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.99840075, 'word': 'Elon Musk', 'start': 0, 'end': 9}, {'entity_group': 'ORG', 'score': 0.9987556, 'word': 'SpaceX', 'start': 18, 'end': 24}, {'entity_group': 'LOC', 'score': 0.99960726, 'word': 'California', 'start': 28, 'end': 38}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883a65c",
   "metadata": {},
   "source": [
    "# ‚≠ê Training Custom NER (Simple Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f7e9f",
   "metadata": {},
   "source": [
    "When default NER doesn‚Äôt detect what you want, you train a custom model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a56f25",
   "metadata": {},
   "source": [
    "### Example: Label **‚ÄúDEVICE‚Äù** for text like ‚ÄúRedmi Note 12‚Äù."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266ff41",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86b1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"I bought a Redmi Note 12 yesterday.\", \n",
    "     {\"entities\": [(11, 25, \"DEVICE\")]}),\n",
    "\n",
    "    (\"The Samsung S22 Ultra is expensive.\", \n",
    "     {\"entities\": [(4, 20, \"DEVICE\")]}),\n",
    "\n",
    "    (\"Xiaomi 14 Pro is a flagship phone.\", \n",
    "     {\"entities\": [(0, 13, \"DEVICE\")]}),\n",
    "\n",
    "    (\"I am planning to buy the Xiaomi 14 Pro.\", \n",
    "     {\"entities\": [(27, 40, \"DEVICE\")]}),\n",
    "\n",
    "    (\"OnePlus 12 is launching next month.\", \n",
    "     {\"entities\": [(0, 10, \"DEVICE\")]}),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95860c30",
   "metadata": {},
   "source": [
    "## Step 2: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d910a8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I am planning to buy the Xiaomi 14 Pro.\" with entities \"[(27, 40, 'DEVICE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 started...\n",
      "Epoch 3 started...\n",
      "Epoch 4 started...\n",
      "Epoch 5 started...\n",
      "Epoch 6 started...\n",
      "Epoch 7 started...\n",
      "Epoch 8 started...\n",
      "Epoch 9 started...\n",
      "Epoch 10 started...\n",
      "Epoch 11 started...\n",
      "Epoch 12 started...\n",
      "Epoch 13 started...\n",
      "Epoch 14 started...\n",
      "Epoch 15 started...\n",
      "Epoch 16 started...\n",
      "Epoch 17 started...\n",
      "Epoch 18 started...\n",
      "Epoch 19 started...\n",
      "Epoch 20 started...\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Create a blank English NLP pipeline\n",
    "# ---------------------------------------------------------\n",
    "# Using blank(\"en\") because we want to train NER from scratch,\n",
    "# not use the default pretrained model.\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Add NER component to the pipeline\n",
    "# ---------------------------------------------------------\n",
    "# \"ner\" = Named Entity Recognizer\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Add the new custom label we want the model to detect\n",
    "# ---------------------------------------------------------\n",
    "ner.add_label(\"DEVICE\")  # Example: Redmi Note 12, Samsung S22\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Initialize the model\n",
    "# ---------------------------------------------------------\n",
    "# This sets up the model weights based on the labels we added.\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Start training loop\n",
    "# ---------------------------------------------------------\n",
    "# We train for several epochs (iterations).\n",
    "# More epochs = better learning, but too many = overfitting.\n",
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch+1} started...\")\n",
    "    \n",
    "    # Loop through each training example\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "\n",
    "        # Step 1: Convert text into a spaCy doc object\n",
    "        doc = nlp.make_doc(text)\n",
    "\n",
    "        # Step 2: Convert your annotation dict into a training Example object\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "\n",
    "        # Step 3: Update the NER model with this example\n",
    "        # sgd = stochastic gradient descent (optimizer)\n",
    "        nlp.update([example], sgd=optimizer)\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3963dec",
   "metadata": {},
   "source": [
    "## Step 3: Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ba48d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xiaomi 14 Pro DEVICE\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Xiaomi 14 Pro is the latest model.\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3890f6",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "* Minimum **200‚Äì500 labelled sentences** for reliable performance\n",
    "* Ensure entity boundaries are correct\n",
    "* Mix short + long sentences\n",
    "* Include variations of names\n",
    "* Add negative examples\n",
    "* Avoid overfitting by adding diverse sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
